{
  "description": "sample MCPspec/ServerRequest.json",
  "meta": {
    "full_size": 8800,
    "stripped_size": 2840,
    "features": [
      "$ref",
      "@minmaxNumber",
      "@siblingKeys",
      "additionalProperties",
      "additionalProperties:object",
      "anyOf",
      "const",
      "enum",
      "format",
      "format:byte",
      "items"
    ],
    "raw_features": [
      "$schema",
      "_boolSchema",
      "definitions",
      "maximum",
      "minimum",
      "properties",
      "required",
      "type",
      "type:[]",
      "type:array",
      "type:integer",
      "type:number",
      "type:object",
      "type:string"
    ]
  },
  "schema": {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "$ref": "#/definitions/ServerRequest",
    "definitions": {
      "ServerRequest": {
        "anyOf": [
          {
            "$ref": "#/definitions/PingRequest"
          },
          {
            "$ref": "#/definitions/CreateMessageRequest"
          },
          {
            "$ref": "#/definitions/ListRootsRequest"
          }
        ]
      },
      "PingRequest": {
        "description": "A ping, issued by either the server or the client, to check that the other party is still alive. The receiver must promptly respond, or else may be disconnected.",
        "properties": {
          "method": {
            "const": "ping",
            "type": "string"
          },
          "params": {
            "additionalProperties": {},
            "properties": {
              "_meta": {
                "properties": {
                  "progressToken": {
                    "$ref": "#/definitions/ProgressToken",
                    "description": "If specified, the caller is requesting out-of-band progress notifications for this request (as represented by notifications/progress). The value of this parameter is an opaque token that will be attached to any subsequent notifications. The receiver is not obligated to provide these notifications."
                  }
                },
                "type": "object"
              }
            },
            "type": "object"
          }
        },
        "required": [
          "method"
        ],
        "type": "object"
      },
      "ProgressToken": {
        "description": "A progress token, used to associate progress notifications with the original request.",
        "type": [
          "string",
          "integer"
        ]
      },
      "CreateMessageRequest": {
        "description": "A request from the server to sample an LLM via the client. The client has full discretion over which model to select. The client should also inform the user before beginning sampling, to allow them to inspect the request (human in the loop) and decide whether to approve it.",
        "properties": {
          "method": {
            "const": "sampling/createMessage",
            "type": "string"
          },
          "params": {
            "properties": {
              "includeContext": {
                "description": "A request to include context from one or more MCP servers (including the caller), to be attached to the prompt. The client MAY ignore this request.",
                "enum": [
                  "allServers",
                  "none",
                  "thisServer"
                ],
                "type": "string"
              },
              "maxTokens": {
                "description": "The maximum number of tokens to sample, as requested by the server. The client MAY choose to sample fewer tokens than requested.",
                "type": "integer"
              },
              "messages": {
                "items": {
                  "$ref": "#/definitions/SamplingMessage"
                },
                "type": "array"
              },
              "metadata": {
                "additionalProperties": true,
                "description": "Optional metadata to pass through to the LLM provider. The format of this metadata is provider-specific.",
                "properties": {},
                "type": "object"
              },
              "modelPreferences": {
                "$ref": "#/definitions/ModelPreferences",
                "description": "The server's preferences for which model to select. The client MAY ignore these preferences."
              },
              "stopSequences": {
                "items": {
                  "type": "string"
                },
                "type": "array"
              },
              "systemPrompt": {
                "description": "An optional system prompt the server wants to use for sampling. The client MAY modify or omit this prompt.",
                "type": "string"
              },
              "temperature": {
                "type": "number"
              }
            },
            "required": [
              "maxTokens",
              "messages"
            ],
            "type": "object"
          }
        },
        "required": [
          "method",
          "params"
        ],
        "type": "object"
      },
      "SamplingMessage": {
        "description": "Describes a message issued to or received from an LLM API.",
        "properties": {
          "content": {
            "anyOf": [
              {
                "$ref": "#/definitions/TextContent"
              },
              {
                "$ref": "#/definitions/ImageContent"
              }
            ]
          },
          "role": {
            "$ref": "#/definitions/Role"
          }
        },
        "required": [
          "content",
          "role"
        ],
        "type": "object"
      },
      "TextContent": {
        "description": "Text provided to or from an LLM.",
        "properties": {
          "annotations": {
            "properties": {
              "audience": {
                "description": "Describes who the intended customer of this object or data is.\n\nIt can include multiple entries to indicate content useful for multiple audiences (e.g., `[\"user\", \"assistant\"]`).",
                "items": {
                  "$ref": "#/definitions/Role"
                },
                "type": "array"
              },
              "priority": {
                "description": "Describes how important this data is for operating the server.\n\nA value of 1 means \"most important,\" and indicates that the data is\neffectively required, while 0 means \"least important,\" and indicates that\nthe data is entirely optional.",
                "maximum": 1,
                "minimum": 0,
                "type": "number"
              }
            },
            "type": "object"
          },
          "text": {
            "description": "The text content of the message.",
            "type": "string"
          },
          "type": {
            "const": "text",
            "type": "string"
          }
        },
        "required": [
          "text",
          "type"
        ],
        "type": "object"
      },
      "Role": {
        "description": "The sender or recipient of messages and data in a conversation.",
        "enum": [
          "assistant",
          "user"
        ],
        "type": "string"
      },
      "ImageContent": {
        "description": "An image provided to or from an LLM.",
        "properties": {
          "annotations": {
            "properties": {
              "audience": {
                "description": "Describes who the intended customer of this object or data is.\n\nIt can include multiple entries to indicate content useful for multiple audiences (e.g., `[\"user\", \"assistant\"]`).",
                "items": {
                  "$ref": "#/definitions/Role"
                },
                "type": "array"
              },
              "priority": {
                "description": "Describes how important this data is for operating the server.\n\nA value of 1 means \"most important,\" and indicates that the data is\neffectively required, while 0 means \"least important,\" and indicates that\nthe data is entirely optional.",
                "maximum": 1,
                "minimum": 0,
                "type": "number"
              }
            },
            "type": "object"
          },
          "data": {
            "description": "The base64-encoded image data.",
            "format": "byte",
            "type": "string"
          },
          "mimeType": {
            "description": "The MIME type of the image. Different providers may support different image types.",
            "type": "string"
          },
          "type": {
            "const": "image",
            "type": "string"
          }
        },
        "required": [
          "data",
          "mimeType",
          "type"
        ],
        "type": "object"
      },
      "ModelPreferences": {
        "description": "The server's preferences for model selection, requested of the client during sampling.\n\nBecause LLMs can vary along multiple dimensions, choosing the \"best\" model is\nrarely straightforward.  Different models excel in different areasâ€”some are\nfaster but less capable, others are more capable but more expensive, and so\non. This interface allows servers to express their priorities across multiple\ndimensions to help clients make an appropriate selection for their use case.\n\nThese preferences are always advisory. The client MAY ignore them. It is also\nup to the client to decide how to interpret these preferences and how to\nbalance them against other considerations.",
        "properties": {
          "costPriority": {
            "description": "How much to prioritize cost when selecting a model. A value of 0 means cost\nis not important, while a value of 1 means cost is the most important\nfactor.",
            "maximum": 1,
            "minimum": 0,
            "type": "number"
          },
          "hints": {
            "description": "Optional hints to use for model selection.\n\nIf multiple hints are specified, the client MUST evaluate them in order\n(such that the first match is taken).\n\nThe client SHOULD prioritize these hints over the numeric priorities, but\nMAY still use the priorities to select from ambiguous matches.",
            "items": {
              "$ref": "#/definitions/ModelHint"
            },
            "type": "array"
          },
          "intelligencePriority": {
            "description": "How much to prioritize intelligence and capabilities when selecting a\nmodel. A value of 0 means intelligence is not important, while a value of 1\nmeans intelligence is the most important factor.",
            "maximum": 1,
            "minimum": 0,
            "type": "number"
          },
          "speedPriority": {
            "description": "How much to prioritize sampling speed (latency) when selecting a model. A\nvalue of 0 means speed is not important, while a value of 1 means speed is\nthe most important factor.",
            "maximum": 1,
            "minimum": 0,
            "type": "number"
          }
        },
        "type": "object"
      },
      "ModelHint": {
        "description": "Hints to use for model selection.\n\nKeys not declared here are currently left unspecified by the spec and are up\nto the client to interpret.",
        "properties": {
          "name": {
            "description": "A hint for a model name.\n\nThe client SHOULD treat this as a substring of a model name; for example:\n - `claude-3-5-sonnet` should match `claude-3-5-sonnet-20241022`\n - `sonnet` should match `claude-3-5-sonnet-20241022`, `claude-3-sonnet-20240229`, etc.\n - `claude` should match any Claude model\n\nThe client MAY also map the string to a different provider's model name or a different model family, as long as it fills a similar niche; for example:\n - `gemini-1.5-flash` could match `claude-3-haiku-20240307`",
            "type": "string"
          }
        },
        "type": "object"
      },
      "ListRootsRequest": {
        "description": "Sent from the server to request a list of root URIs from the client. Roots allow\nservers to ask for specific directories or files to operate on. A common example\nfor roots is providing a set of repositories or directories a server should operate\non.\n\nThis request is typically used when the server needs to understand the file system\nstructure or access specific locations that the client has permission to read from.",
        "properties": {
          "method": {
            "const": "roots/list",
            "type": "string"
          },
          "params": {
            "additionalProperties": {},
            "properties": {
              "_meta": {
                "properties": {
                  "progressToken": {
                    "$ref": "#/definitions/ProgressToken",
                    "description": "If specified, the caller is requesting out-of-band progress notifications for this request (as represented by notifications/progress). The value of this parameter is an opaque token that will be attached to any subsequent notifications. The receiver is not obligated to provide these notifications."
                  }
                },
                "type": "object"
              }
            },
            "type": "object"
          }
        },
        "required": [
          "method"
        ],
        "type": "object"
      }
    }
  },
  "tests": [
    {
      "description": "llama 70b generated positive",
      "valid": true,
      "data": {
        "method": "sampling/createMessage",
        "params": {
          "messages": [
            {
              "role": "assistant",
              "content": {
                "text": "Hello, how are you?",
                "type": "text"
              }
            }
          ],
          "maxTokens": 10,
          "includeContext": "none",
          "temperature": 0.5,
          "stopSequences": [
            ".\n"
          ],
          "modelPreferences": {
            "intelligencePriority": 0.8,
            "speedPriority": 0.2,
            "costPriority": 0,
            "hints": [
              {
                "name": "claude-3-5-sonnet"
              }
            ]
          }
        }
      }
    },
    {
      "description": "llama-70b generated negative",
      "valid": false,
      "rust_error": "{\"method\":\"sampling/createMessage\",\"params\":{\"messages\":[{\"role\":\"assistant\",\"content\":{\"text\":\"Hello, how are you?\",\"type\":\"text\",\"priority\":2}}],\"maxTokens\":10,\"includeContext\":\"none\",\"temperature\":1.5,\"stopSequences\":[\".\\n\"],\"modelPreferences\":{\"intelligencePriority\":1.2,\"speedPriority\":0.2,\"costPriority\":0,\"hints\":[{\"name\":\"claude-3-5-sonnet\"}]}}} is not valid under any of the schemas listed in the 'anyOf' keyword",
      "python_error": "1.2 is greater than the maximum of 1\n\nFailed validating 'maximum' in schema[1]['properties']['params']['properties']['modelPreferences']['properties']['intelligencePriority']:\n    {'description': 'How much to prioritize intelligence and capabilities '\n                    'when selecting a\\n'\n                    'model. A value of 0 means intelligence is not '\n                    'important, while a value of 1\\n'\n                    'means intelligence is the most important factor.',\n     'maximum': 1,\n     'minimum': 0,\n     'type': 'number'}\n\nOn instance['params']['modelPreferences']['intelligencePriority']:\n    1.2",
      "data": {
        "method": "sampling/createMessage",
        "params": {
          "messages": [
            {
              "role": "assistant",
              "content": {
                "text": "Hello, how are you?",
                "type": "text",
                "priority": 2
              }
            }
          ],
          "maxTokens": 10,
          "includeContext": "none",
          "temperature": 1.5,
          "stopSequences": [
            ".\n"
          ],
          "modelPreferences": {
            "intelligencePriority": 1.2,
            "speedPriority": 0.2,
            "costPriority": 0,
            "hints": [
              {
                "name": "claude-3-5-sonnet"
              }
            ]
          }
        }
      }
    }
  ]
}